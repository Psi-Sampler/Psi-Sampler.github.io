---
layout: ../layouts/Layout.astro
title: "Î¨-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models"
description: "Hello world!"
title2: ""
---

import { Image } from "astro:assets";

import Layout from "../layouts/Layout.astro";

import Header from "../components/Header.astro";
import TwoColumns from "../components/TwoColumns.astro";
import Video from "../components/Video.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import PDF from "../components/PDF.astro";
import Figure from "../components/Figure.astro";
import LaTeX from "../components/LaTeX.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Splat from "../components/Splat.tsx"
import Carousel from "../components/Carousel.astro";
import GeneralCarousel from "../components/GeneralCarousel.astro";
import EnumCarousel from "../components/EnumCarousel.astro";
import ModelViewer from "../components/ModelViewer.astro";
import ImageComparison from "../components/ImageComparison.astro";

import CodeBlock from "../components/CodeBlock.astro";
export const components = {pre: CodeBlock}

import teaser from "../assets/teaser.png";
import toy from "../assets/toy.png";
import layout from "../assets/layout.png";
import counting from "../assets/counting.png";
import aesthetic from "../assets/aesthetic.png";

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Taehoon Yoon*",
      url: "https://github.com/taehoon-yoon",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Yunhong Min*",
      url: "https://cactus-save-5ac.notion.site/4020147bcaef4257888b08b0a4ef238d",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Kyeongmin Yeo*",
      url: "https://32v.github.io/",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Minhyuk Sung",
      url: "https://mhsung.github.io/",
      institution: "KAIST",
      notes: [],
    },
  ]}
  notes={[
    { symbol: "*", text: "Equal contribution" },
  ]}
  links={[
    {
      name: "Paper",
      url: "https://arxiv.org/pdf/2506.01320",
      icon: "fa-solid:file-pdf",
    },
    {
      name: "arXiv",
      url: "https://arxiv.org/abs/2506.01320",
      icon: "academicons:arxiv",
    },
    {
      name: "Code",
      url: "https://github.com/KAIST-Visual-AI-Group/Psi-Sampler",
      icon: "mdi:github",
    },
  ]}
/>

<Figure caption="We propose Î¨-Sampler, an SMC-based framework that improves inference-time reward alignment in score-based generative models via efficient posterior initialization using the pCNL algorithm.">
  <Image src={teaser} alt="" />
</Figure>
---


## Abstract

We introduce <LaTeX inline formula="\Psi" />-Sampler, an SMC-based framework incorporating pCNL-based initial particle sampling for effective inference-time reward alignment with a score-based generative model. Inference-time reward alignment with score-based generative models has recently gained significant traction, following a broader paradigm shift from pre-training to post-training optimization. At the core of this trend is the application of Sequential Monte Carlo (SMC) to the denoising process. However, existing methods typically initialize particles from the Gaussian prior, which inadequately captures reward-relevant regions and results in reduced sampling efficiency. We demonstrate that initializing from the reward-aware posterior significantly improves alignment performance. To enable posterior sampling in high-dimensional latent spaces, we introduce the preconditioned Crankâ€“Nicolson Langevin (pCNL) algorithm, which combines dimension-robust proposals with gradient-informed dynamics. This approach enables efficient and scalable posterior sampling and consistently improves performance across various reward alignment tasks, including layout-to-image generation, quantity-aware generation, and aesthetic-preference generation, as demonstrated in our experiments. 

---

## Toy Experiment: Comparing SMC Initialization Methods

<Image src={toy} alt="" />

We visualize how different initialization strategies affect the performance of Sequential Monte Carlo (SMC) in a synthetic 2D task.

(A) shows raw samples from the prior distribution (blue), without reward guidance.

(B) shows the target distribution (red), defined by a reward that selects specific modes from the ground-truth.

Each panel overlays:

ðŸ”´ Red dots: clean data samples from the desired target distribution.

ðŸ”µ Blue dots: initial samples used to start SMC inference.

While standard SMC (C) fails to cover all modes, and Metropolis-Adjusted Langevin
 Algorithm (MALA) + SMC (D) still leaves some gaps, our proposed <LaTeX inline formula="\Psi" />-Sampler (E) achieves the closest match to the target. This highlights the importance of high-quality initial particles in reward-guided inference.

<div class="mt-7"></div>
# Qualitative Results
<div class="mt-2"></div>
We provide qualitative results comparing various baselines with our <LaTeX inline formula="\Psi" />-Sampler. 
We conducted experiments on three applications: **Layout-to-Image Generation**, **Quantity-Aware Image Generation**, and **Aesthetic-Preference Image Generation**.

**Single-Particle:** *FreeDoM* [[1](#ref-free)] is a non-SMC method that relies on a single particle.  
**SMC with Prior Initialization:** *TDS* [[2](#ref-wu)] serves as the SMC baseline, while *DAS* [[3](#ref-kim)] extends it with a tempering strategy.  
**SMC with Posterior Initialization:** We compare four posterior-based initialization strategies: â€” *Top-K-of-N*, *Unadjusted Langevin Algorithm (ULA)*, *Metropolis-Adjusted Langevin
 Algorithm (MALA)*, and our proposed <LaTeX inline formula="\Psi" />-Sampler.  

For all applications, <LaTeX inline formula="\Psi" />-Sampler demonstrates the highest compliance with the given conditions. Additional qualitative results are provided in the main paper.

## Layout-to-Image generation
<Image src={layout} alt="" />

## Quantity-Aware Image Generation
<Image src={counting} alt="" />

## Aesthetic-Preference Image Generation
<Image src={aesthetic} alt="" />

## References

<div class="text-sm leading-relaxed space-y-2">
  <div id="ref-free">
    [1] Jiwen Yu et al. [*FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model*](https://arxiv.org/abs/2303.09833), ICCV 2023.
  </div>

  <div id="ref-wu">
    [2] Luhuan Wu et al. [*Practical and Asymptotically Exact Conditional Sampling in Diffusion Models*](https://arxiv.org/abs/2306.17775), NeurIPS 2023.
  </div>
  
  <div id="ref-kim">
    [3] Sunwoo Kim et al. [*Test-time Alignment of Diffusion Models without Reward Over-optimization*](https://arxiv.org/abs/2501.05803), ICLR 2025.
  </div>
</div>

## Citation

If you find our work helpful, please cite our paper.

```bibtex
@misc{yoon2025psisamplerinitialparticlesampling,
      title={$\Psi$-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models}, 
      author={Taehoon Yoon and Yunhong Min and Kyeongmin Yeo and Minhyuk Sung},
      year={2025},
      eprint={2506.01320},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.01320}, 
}
---
layout: ../layouts/Layout.astro
title: "Œ®-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models"
description: "Hello world!"
title2: ""
---

import { Image } from "astro:assets";

import Layout from "../layouts/Layout.astro";

import Header from "../components/Header.astro";
import TwoColumns from "../components/TwoColumns.astro";
import Video from "../components/Video.astro";
import YouTubeVideo from "../components/YouTubeVideo.astro";
import PDF from "../components/PDF.astro";
import Figure from "../components/Figure.astro";
import LaTeX from "../components/LaTeX.astro";
import SmallCaps from "../components/SmallCaps.astro";
import Splat from "../components/Splat.tsx"
import Carousel from "../components/Carousel.astro";
import GeneralCarousel from "../components/GeneralCarousel.astro";
import EnumCarousel from "../components/EnumCarousel.astro";
import ModelViewer from "../components/ModelViewer.astro";
import ImageComparison from "../components/ImageComparison.astro";

import CodeBlock from "../components/CodeBlock.astro";
export const components = {pre: CodeBlock}

import teaser from "../assets/teaser.png";
import toy from "../assets/toy.png";
import layout from "../assets/layout.png";
import counting from "../assets/counting.png";
import aesthetic from "../assets/aesthetic.png";

<Header
  title={frontmatter.title}
  authors={[
    {
      name: "Taehoon Yoon*",
      url: "https://github.com/taehoon-yoon",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Yunhong Min*",
      url: "https://cactus-save-5ac.notion.site/4020147bcaef4257888b08b0a4ef238d",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Kyeongmin Yeo*",
      url: "https://32v.github.io/",
      institution: "KAIST",
      notes: [],
    },
    {
      name: "Minhyuk Sung",
      url: "https://mhsung.github.io/",
      institution: "KAIST",
      notes: [],
    },
  ]}
  notes={[
    { symbol: "*", text: "Equal contribution" },
  ]}
  links={[
    {
      name: "Paper",
      url: "https://arxiv.org/pdf/2506.01320",
      icon: "fa-solid:file-pdf",
    },
    {
      name: "arXiv",
      url: "https://arxiv.org/abs/2506.01320",
      icon: "academicons:arxiv",
    },
    {
      name: "Code",
      url: "https://github.com/KAIST-Visual-AI-Group/Psi-Sampler",
      icon: "mdi:github",
    },
  ]}
/>

<Figure caption="We propose Œ®-Sampler, an SMC-based framework that improves inference-time reward alignment in score-based generative models via efficient posterior initialization using the pCNL algorithm.">
  <Image src={teaser} alt="" />
</Figure>
---


## Abstract

We introduce <LaTeX inline formula="\Psi" />-Sampler, an SMC-based framework incorporating pCNL-based initial particle sampling for effective inference-time reward alignment with a score-based generative model. Inference-time reward alignment with score-based generative models has recently gained significant traction, following a broader paradigm shift from pre-training to post-training optimization. At the core of this trend is the application of Sequential Monte Carlo (SMC) to the denoising process. However, existing methods typically initialize particles from the Gaussian prior, which inadequately captures reward-relevant regions and results in reduced sampling efficiency. We demonstrate that initializing from the reward-aware posterior significantly improves alignment performance. To enable posterior sampling in high-dimensional latent spaces, we introduce the preconditioned Crank‚ÄìNicolson Langevin (pCNL) algorithm, which combines dimension-robust proposals with gradient-informed dynamics. This approach enables efficient and scalable posterior sampling and consistently improves performance across various reward alignment tasks, including layout-to-image generation, quantity-aware generation, and aesthetic-preference generation, as demonstrated in our experiments. 

---

## Toy Experiment: Comparing SMC Initialization Methods

<Image src={toy} alt="" />

We visualize how different initialization strategies affect the performance of Sequential Monte Carlo (SMC) in a synthetic 2D task.

(A) shows raw samples from the prior distribution (blue), and the generation results from the pre-trained score-based generative model without reward guidance (red).

(B) shows the target distribution (red) defined by a reward that selects specific modes, and the posterior distribution (blue).

Each panel (C)-(E) overlays:

üî¥ Red dots: clean data samples obtained through SMC with inference-time reward alignment, where the proposal kernel is based on the denoising process of pre-trained score-based generative model.

üîµ Blue dots: initial samples used to start SMC sampling.

While standard SMC (C) fails to cover all modes, and Metropolis-Adjusted Langevin
 Algorithm (MALA) + SMC (D) still leaves some gaps, our proposed <LaTeX inline formula="\Psi" />-Sampler (E) achieves the closest match to the target. This highlights the importance of high-quality initial particles in reward-guided inference.

<div class="mt-7"></div>
# Qualitative Results
<div class="mt-2"></div>
We provide qualitative results comparing various baselines with our <LaTeX inline formula="\Psi" />-Sampler. 
We conducted experiments on three applications: **Layout-to-Image Generation**, **Quantity-Aware Image Generation**, and **Aesthetic-Preference Image Generation**.

**Single-Particle:** *FreeDoM* [[1](#ref-free)] is a non-SMC method that relies on a single particle.  
**SMC Initialized with Prior Distribution Samples:** *TDS* [[2](#ref-wu)] serves as the SMC baseline, while *DAS* [[3](#ref-kim)] extends it with a tempering strategy.  
**SMC Initialized with Posterior Distribution Samples:** We compare four posterior-based initialization strategies: ‚Äî *Top-K-of-N*, *Unadjusted Langevin Algorithm (ULA)*, *Metropolis-Adjusted Langevin
 Algorithm (MALA)*, and our proposed <LaTeX inline formula="\Psi" />-Sampler.  

For all applications, <LaTeX inline formula="\Psi" />-Sampler demonstrates the highest compliance with the given conditions. Additional qualitative results are provided in the main paper.

## Layout-to-Image Generation
Each example visualizes the input layout with color-coded phrases and their corresponding bounding boxes for clarity.
<LaTeX inline formula="\Psi" />-Sampler consistently respects both the spatial
constraints and object presence specified in the layout.

<Image src={layout} alt="" />

## Quantity-Aware Image Generation
For each image, we overlay the predicted object centroids from a counting model for easier comparison.
Additionally, we display the predicted count below each image, along with the absolute
difference from the target quantity in the format (<LaTeX inline formula="\Delta \cdot" />).
<LaTeX inline formula="\Psi" />-Sampler consistently consistently produces the most accurate results in the quantity-aware image generation task, successfully matching the specified object counts more closely than competing methods.

<Image src={counting} alt="" />

## Aesthetic-Preference Image Generation
For each prompt (e.g., ‚ÄúHorse‚Äù, ‚ÄúBird‚Äù), we show the predicted
aesthetic score [[4](#ref-aes)] below each image. While all methods generate visually plausible outputs, <LaTeX inline formula="\Psi" />-Sampler consistently produces images with higher aesthetic appeal, as reflected in both qualitative
impressions and the predicted aesthetic scores.

<Image src={aesthetic} alt="" />

## References

<div class="text-sm leading-relaxed space-y-2">
  <div id="ref-free">
    [1] Jiwen Yu et al. [*FreeDoM: Training-Free Energy-Guided Conditional Diffusion Model*](https://arxiv.org/abs/2303.09833), ICCV 2023.
  </div>

  <div id="ref-wu">
    [2] Luhuan Wu et al. [*Practical and Asymptotically Exact Conditional Sampling in Diffusion Models*](https://arxiv.org/abs/2306.17775), NeurIPS 2023.
  </div>
  
  <div id="ref-kim">
    [3] Sunwoo Kim et al. [*Test-time Alignment of Diffusion Models without Reward Over-optimization*](https://arxiv.org/abs/2501.05803), ICLR 2025.
  </div>

  <div id="ref-aes">
    [4] Christoph Schuhmann. [*Laion aesthetic predictor*](https://laion.ai/blog/laion-aesthetics/)
  </div>
</div>

## Citation

If you find our work helpful, please cite our paper.

```bibtex
@misc{yoon2025psisamplerinitialparticlesampling,
      title={$\Psi$-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models}, 
      author={Taehoon Yoon and Yunhong Min and Kyeongmin Yeo and Minhyuk Sung},
      year={2025},
      eprint={2506.01320},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.01320}, 
}